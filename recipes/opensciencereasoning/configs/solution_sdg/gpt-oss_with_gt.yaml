cluster: local
base_output_dir: "/workspace/opensciencereasoning/gpt-oss"
expname: "gpt-oss-generate-solutions"
suffix: ""  # Suffix for experiment names
dataset_name: ""  # Optional dataset name for id generation


# Input file for the first stage (generate_solutions)
# It must include the field "problem"
# All the data in this file will be processed with the same prompt
# Make sure the problems fit the prompt you are using
input_file: ""

# Can define initial dependency for the `generate_solutions` stage to run after
initial_dependency: None

# Define the full sequence of stages for this mode
pipeline_stages:
  - filter_problems          # Filter problems based on format
  - decontaminate            # Decontaminate problems
  - topics_labeling          # Label topics and subtopics
  - difficulty_estimation    # Estimate difficulty of problems
  - generate_solutions       # Generate solutions
  - aggregate                # Aggregate all the metadata into a single file

# Directory structure configuration
directories:
  step-0-filter-problems: ${base_output_dir}/solution-sdg/step-0-filter-problems
  step-1-decontaminate: ${base_output_dir}/solution-sdg/step-1-decontaminate
  step-2-topics-labeling: ${base_output_dir}/solution-sdg/step-2-topics-labeling
  step-3-difficulty-estimation: ${base_output_dir}/solution-sdg/step-3-difficulty-estimation
  step-4-generate-solutions: ${base_output_dir}/solution-sdg/step-4-generate-solutions
  step-5-aggregate: ${base_output_dir}/solution-sdg/step-5-aggregate

# Stage-specific configurations
stages:
  filter_problems:
    output_dir: ${directories.step-0-filter-problems}
    input_file: ${input_file}
    dataset_name: ${dataset_name}
    remove_images: True
    num_options: null
    option_format_regex: null
    deduplicate: True
  
  decontaminate:
    output_dir: ${directories.step-1-decontaminate}
    input_file: ${directories.step-0-filter-problems}/final_result.jsonl
    test_sets:
      - ["hle", "text"]
      - ["mmlu", "test"]
      - ["mmlu-pro", "test"]
      - ["gpqa", "diamond"]
    model: /hf_models/Qwen2.5-32B-Instruct
    server_type: sglang
    server_gpus: 1
    server_nodes: 1
    dependent_jobs: 1
    num_chunks: 20
    dependencies:
      - filter_problems

  topics_labeling:
    output_dir: ${directories.step-2-topics-labeling}
    input_file: ${directories.step-1-decontaminate}/final_result.jsonl
    model: /hf_models/Qwen2.5-32B-Instruct
    dependencies:
      - decontaminate
    server_type: sglang
    server_gpus: 8
    server_nodes: 1
    dependent_jobs: 1
    num_chunks: 5
    generation_keys:
      - topic
      - subtopic
    few_shots_name: stem_topics
    topic:
      - Mathematics
      - Chemistry
      - Physics
      - Biology
    subtopic:
      Chemistry:
        - Organic Chemistry
        - Inorganic Chemistry
        - General Chemistry
      Physics:
        - Quantum Mechanics
        - Classical Mechanics
        - General Physics
        - Relativistic Mechanics
        - Electromagnetism and Photonics
        - Optics and Acoustics
        - Condensed Matter Physics
        - High-energy Particle Physics
        - Astrophysics
      Biology:
        - Genetics
        - Molecular Biology
        - General Biology

  difficulty_estimation:
    output_dir: ${directories.step-3-difficulty-estimation}
    input_file: ${directories.step-1-decontaminate}/final_result.jsonl  # Should have expected answers

    generation_kwargs:
      params:
        model: /hf_models/Qwen3-30B-A3B
        server_type: vllm
        server_gpus: 8
        server_nodes: 2
        dependent_jobs: 1
        num_random_seeds: 5
        num_chunks: 20
      ctx_params:
        prompt_config: generic/general-boxed
        inference.tokens_to_generate: 16000
    
    judge_kwargs:
      params:
        model: /hf_models/Qwen2.5-32B-Instruct
        server_type: vllm
        server_gpus: 8
        server_nodes: 1
        num_random_seeds: ${stages.difficulty_estimation.generation_kwargs.params.num_random_seeds}
        dependent_jobs: 1
        num_chunks: 5
      ctx_params:
        prompt_config: judge/general-judge
    
    dependencies:
      - decontaminate
  
  generate_solutions:
    make_majority_voting: False
    output_dir: ${directories.step-4-generate-solutions}
    predicted_answer_regex: null
    make_judgement: True
  
    generation_kwargs:
      params:
        input_file: ${directories.step-1-decontaminate}/final_result.jsonl
        model: /hf_models/gpt-oss-120b
        server_type: vllm
        server_gpus: 8
        server_nodes: 1
        dependent_jobs: 1
        num_chunks: 20
        num_random_seeds: 5
        with_sandbox: True
        server_args: "--async-scheduling"
  
      ctx_params:
        prompt_config: generic/general-boxed
        code_tags: gpt-oss
        code_execution: true
        max_concurrent_requests: 1024
        inference.tokens_to_generate: 16000
        inference.extra_body.reasoning_effort: high
        inference.endpoint_type: text
        inference.temperature: 1.0
        inference.top_p: 1.0
        server.code_execution.max_code_executions: 100
        chat_template_kwargs.reasoning_effort: high
        chat_template_kwargs.builtin_tools: [python]

    judge_kwargs:
      ctx_params:
        prompt_config: judge/general-judge
      params:
        model: /hf_models/Qwen2.5-32B-Instruct
        server_type: vllm
        server_gpus: 8
        server_nodes: 1
        num_random_seeds: ${stages.generate_solutions.generation_kwargs.params.num_random_seeds}
        dependent_jobs: 1
        num_chunks: 5
  
    dependencies:
      - decontaminate
  
  aggregate:
    output_dir: ${directories.step-5-aggregate}
    solutions_path: ${directories.step-4-generate-solutions}/final_result.jsonl
    metadata_files: 
      - ${directories.step-2-topics-labeling}/final_result.jsonl
      - ${directories.step-3-difficulty-estimation}/final_result.jsonl
    dependencies:
      - topics_labeling
      - difficulty_estimation
      - generate_solutions
