cluster: local
base_output_dir: "/workspace/opensciencereasoning/gpt-oss"
expname: "gpt-oss-generate-solutions"
suffix: ""  # Suffix for experiment names
dataset_name: ""  # Optional dataset name for id generation

# Input file for the first stage (generate_solutions)
# It must include the field "problem"
# All the data in this file will be processed with the same prompt
# Make sure the problems fit the prompt you are using
input_file: ""

# Can define initial dependency for the `generate_solutions` stage to run after
initial_dependency: None

# Define the full sequence of stages for this mode
pipeline_stages:
  - filter_problems          # Filter problems based on format
  - decontaminate            # Decontaminate problems
  - topics_labeling          # Label topics and subtopics
  - difficulty_estimation    # Estimate difficulty of problems
  - aggregate                # Aggregate all the metadata into a single file
  - filter_solutions         # Filter solutions
  - prepare_for_sft          # Prepare for SFT

# Directory structure configuration
directories:
  step-0-filter-problems: ${base_output_dir}/solution-sdg/step-0-filter-problems
  step-1-decontaminate: ${base_output_dir}/solution-sdg/step-1-decontaminate
  step-2-topics-labeling: ${base_output_dir}/solution-sdg/step-2-topics-labeling
  step-3-difficulty-estimation: ${base_output_dir}/solution-sdg/step-3-difficulty-estimation
  step-4-aggregate: ${base_output_dir}/solution-sdg/step-4-aggregate
  step-5-filter-solutions: ${base_output_dir}/solution-sdg/step-5-filter-solutions
  step-6-prepare-for-sft: ${base_output_dir}/solution-sdg/step-6-prepare-for-sft

# Stage-specific configurations
stages:
  filter_problems:
    output_dir: ${directories.step-0-filter-problems}
    input_file: ${input_file}
    dataset_name: ${dataset_name}
    problem_field: problem
    expected_answer_field: expected_answer
    id_field: id
    remove_images: True
    num_options: null
    option_format_regex: null
    deduplicate: True
  
  decontaminate:
    output_dir: ${directories.step-1-decontaminate}
    input_file: ${directories.step-0-filter-problems}/final_result.jsonl
    test_sets:
      - ["hle", "text"]
      - ["mmlu", "test"]
      - ["mmlu-pro", "test"]
      - ["gpqa", "diamond"]
    model: /hf_models/Qwen2.5-32B-Instruct
    server_type: sglang
    server_gpus: 1
    server_nodes: 1
    dependent_jobs: 1
    num_chunks: 20
    dependencies:
      - filter_problems

  topics_labeling:
    output_dir: ${directories.step-2-topics-labeling}
    input_file: ${directories.step-1-decontaminate}/final_result.jsonl
    model: /hf_models/Qwen2.5-32B-Instruct
    dependencies:
      - decontaminate
    server_type: sglang
    server_gpus: 8
    server_nodes: 1
    dependent_jobs: 1
    num_chunks: 5
    generation_keys:
      - topic
      - subtopic
    few_shots_name: stem_topics
    topic:
      - Mathematics
      - Chemistry
      - Physics
      - Biology
    subtopic:
      Chemistry:
        - Organic Chemistry
        - Inorganic Chemistry
        - General Chemistry
      Physics:
        - Quantum Mechanics
        - Classical Mechanics
        - General Physics
        - Relativistic Mechanics
        - Electromagnetism and Photonics
        - Optics and Acoustics
        - Condensed Matter Physics
        - High-energy Particle Physics
        - Astrophysics
      Biology:
        - Genetics
        - Molecular Biology
        - General Biology

    
  difficulty_estimation:
    output_dir: ${directories.step-3-difficulty-estimation}
    input_file: ${directories.step-1-decontaminate}/final_result.jsonl  # Should have expected answers

    generation_kwargs:
      params:
        model: /hf_models/Qwen3-30B-A3B
        server_type: vllm
        server_gpus: 8
        server_nodes: 2
        dependent_jobs: 1
        num_random_seeds: 5
        num_chunks: 20
      ctx_params:
        prompt_config: generic/general-boxed
        inference.tokens_to_generate: 16000
    
    judge_kwargs:
      params:
        model: /hf_models/Qwen2.5-32B-Instruct
        server_type: vllm
        server_gpus: 8
        server_nodes: 1
        num_random_seeds: ${stages.difficulty_estimation.generation_kwargs.params.num_random_seeds}
        dependent_jobs: 1
        num_chunks: 5
      ctx_params:
        prompt_config: judge/general-judge

  aggregate:
    output_dir: ${directories.step-4-aggregate}
    metadata_files: 
      - ${directories.step-2-topics-labeling}/final_result.jsonl
      - ${directories.step-3-difficulty-estimation}/final_result.jsonl
    dependencies:
      - topics_labeling
      - difficulty_estimation

  filter_solutions:
    output_dir: ${directories.step-5-filter-solutions}
    input_file: ${directories.step-4-aggregate}/final_result.jsonl
    only_correct_solutions: True
    generation_model_pass_rate_range: [-1.0, 1.0] # minimum exclusive, maximum inclusive
    pass_rate_range: [-1.0, 1.0] # minimum exclusive, maximum inclusive
    metadata_values:
      topic: ["Biology", "Chemistry", "Physics", "Mathematics", "Other", "undefined"]
    dependencies:
      - aggregate
  
  prepare_for_sft:
    output_dir: ${directories.step-6-prepare-for-sft}
    input_file: ${directories.step-5-filter-solutions}/final_result.jsonl
    prompt_config: generic/math
    tokenizer: openai/gpt-oss-120b
    dependencies:
      - filter_solutions
